{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4496ae45-d5fe-49b3-aba4-3052471576df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## [Property Tax Parcels](https://www.mass.gov/info-details/massgis-data-property-tax-parcels)\n",
       "\n",
       "\n",
       "MassGIS standardized assessors parcel mapping data set contains property (land lot) boundaries and database information from each community's assessor.   \n",
       "Historic tax parcels are available.\n",
       "\n",
       "Read the [overview](https://www.mass.gov/info-details/massgis-data-property-tax-parcels#overview-)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(\"parcels.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e2ca8-a9ca-4706-9030-6f124da0eec2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851de550-a44b-4bbc-95aa-3580e827ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv (\n",
    "        find_dotenv (\n",
    "            usecwd=True\n",
    "        ),\n",
    "    override=True\n",
    ") # read local .env file and override any existing\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from os import environ\n",
    "\n",
    "username     =  environ.get(\"POSTGRES_USERNAME\", \"postgres\")\n",
    "password     =  environ.get(\"POSTGRES_PASSWORD\", \"postgres\")\n",
    "ipaddress    =  environ.get(\"POSTGRES_IPADDRESS\", \"localhost\")\n",
    "port         =  environ.get(\"POSTGRES_PORT\", \"5432\")\n",
    "dbname       =  environ.get(\"POSTGRES_DBNAME\", \"ArlingtonMA\")\n",
    "\n",
    "#establish database connection for Transform queries and Loads\n",
    "cnx= create_engine(f'postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab38591d-0d0e-487b-9464-8aac4b2e490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad121cfd-ba7d-470f-93ca-ae4330511f41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971b5a7-dc5d-44c7-b0eb-fc479b90a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MassGIS_Level3_TaxParcels (\n",
    "    url    = 'zip+http://download.massgis.digital.mass.gov/gdbs/l3parcels/M010_parcels_gdb.zip',\n",
    "    debug  =  False\n",
    ") :\n",
    "    import  geopandas  as  gpd\n",
    "    # for current use:\n",
    "    # url = 'zip+http://download.massgis.digital.mass.gov/gdbs/l3parcels/M{dor}_parcels_gdb.zip'.format(dor=dor)\n",
    "\n",
    "    ## Level3 Assessor Parcels with parcel geometry \n",
    "    ## in TaxPar layer and property information in Assess layer\n",
    "    ## return EPSG 4326, lat/lon, coordinate system\n",
    "   \n",
    "    import fiona\n",
    "\n",
    "    layers  =  fiona.listlayers ( url )\n",
    "    TaxPar  =  layers [ 0 ]\n",
    "    Assess  =  layers [ 1 ]\n",
    "    l3      =  { }  \n",
    "    \n",
    "    for idx in range ( len ( layers ) ) :\n",
    "        l3 [ layers [ idx ] ]  =  gpd . read_file ( url , layer = idx, dtype = str )\n",
    "        if debug :\n",
    "            print ( idx , layers [ idx ] , len ( l3 [ layers [ idx ] ] ) )\n",
    "        \n",
    "    ##layer 1 Assess has geomtery column all None\n",
    "    l3 [ Assess ] . drop ( 'geometry' , axis = 1 , inplace = True )\n",
    "\n",
    "    combo  =  l3 [ TaxPar ] . merge ( l3 [ Assess ] , on = [ 'TOWN_ID' , 'LOC_ID' ] , how = 'outer' , indicator = True )\n",
    "    combo  =  combo [ combo . _merge == 'both' ] . reset_index ( drop = True )   ##63 no matches for Arlington; water, roads, etc.\n",
    "    combo . drop ( '_merge' , axis = 1 , inplace = True )\n",
    "    \n",
    "    for col in [ 'YEAR_BUILT' , 'BLD_AREA' , 'UNITS' , 'RES_AREA' ] :\n",
    "        combo [ col ] = combo [ col ] . fillna ( 0 ) . astype ( int )\n",
    "\n",
    "    \n",
    "    return  gpd . GeoDataFrame ( \n",
    "        combo , \n",
    "        geometry = combo . geometry\n",
    "    ) . to_crs ( \"EPSG:4326\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf17c53-3f15-4e58-b190-32e4c7e9c4df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f92fba1-dcf1-426b-8281-e602889d30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_property_assessments_table(df):\n",
    "    \n",
    "    cols = ['FY','LOC_ID', 'PROP_ID', 'BLDG_VAL', 'LAND_VAL',\n",
    "           'OTHER_VAL', 'TOTAL_VAL', 'LOT_SIZE', 'SHAPE_Area', 'LS_DATE', 'LS_PRICE',\n",
    "           'USE_CODE', 'SITE_ADDR', 'ADDR_NUM', 'FULL_STR', 'LOCATION', \n",
    "           'ZIP', 'OWNER1', 'OWN_CITY', 'OWN_STATE',\n",
    "           'LS_BOOK', 'LS_PAGE', 'ZONING', 'YEAR_BUILT',\n",
    "           'BLD_AREA', 'UNITS', 'RES_AREA', 'STYLE', 'STORIES', 'NUM_ROOMS',\n",
    "           'LOT_UNITS', 'geometry']\n",
    "    newcols = ['year','loc_id','pid','building','land','other','total',\n",
    "               'lot_size','area','last_sale_date','last_sale_price','land_use',\n",
    "                'address','street_num','street_name','unit','zip',\n",
    "               'owner','owner_city','owner_state','book','page',\n",
    "               'zoning','year_built','building_area','units',\n",
    "               'living_area','style','stories','rooms','lot_units','geometry']\n",
    "\n",
    "    assess = df[cols].copy().rename(columns=dict(zip(cols,newcols)))\n",
    "\n",
    "    assess['last_sale_date'] = pd.to_datetime(assess['last_sale_date']).dt.strftime('%Y-%m-%d')\n",
    "    assess['area']   =  assess['area']/0.09290304 #sq meter to sq ft\n",
    "    assess['unit']   =  assess['unit'].astype(str).str.replace(\"#\",\"\")\n",
    "    assess['zoning'] =  assess['zoning'].str.upper()\n",
    "    \n",
    "    ## some early loc_id used meters instead of feet\n",
    "    mask = assess.loc_id.str.contains('M_')\n",
    "    if(mask.any()):\n",
    "        print('M_ in loc_id')\n",
    "    assess.loc[mask,'loc_id'] = 'F_'+\\\n",
    "        (assess.loc[mask,'loc_id'].str.split('_').str[1].astype(float)*3.280839895).apply(round,0).astype(int).astype(str) +\\\n",
    "        '_' +\\\n",
    "        (assess.loc[mask,'loc_id'].str.split('_').str[2].astype(float)*3.280839895).apply(round,0).astype(int).astype(str)\n",
    "    \n",
    "    ## enforce types\n",
    "    for col in ['year','building','land_use','other','total','last_sale_price','area',\n",
    "                'year_built','building_area','units','living_area','rooms']:\n",
    "        assess[col]=assess[col].fillna(0).astype(int)\n",
    "\n",
    "    assess = assess.drop(['lot_size','lot_units'],axis=1)\n",
    "\n",
    "    return assess\n",
    "\n",
    "def remove_dup_loc_id_round_geometry(df):\n",
    "    import geopandas as gpd\n",
    "    from shapely.wkt import loads\n",
    "    import re\n",
    "\n",
    "    simpledec = re.compile(r\"\\d*\\.\\d+\")\n",
    "    def mround(match):\n",
    "        return \"{:.7f}\".format(float(match.group()))\n",
    "\n",
    "    rdf = gpd.GeoDataFrame(df)\n",
    "    rdf.geometry = rdf.geometry.apply(lambda x: loads(re.sub(simpledec, mround, x.wkt)))\n",
    "\n",
    "    return rdf\n",
    "\n",
    "def create_geometry(parcels):\n",
    "\n",
    "    import geopandas as gpd\n",
    "    \n",
    "    parcels = parcels[parcels.year>2013].sort_values(['pid','year'])\n",
    "    pid_2_address  =  parcels [ ['pid','street_name','street_num','unit'] ].copy()\n",
    "    pid_2_address  =  pid_2_address . replace ( { None : '' , pd.isnull : '' } )\n",
    "    pid_2_address  =  pid_2_address [ ~pid_2_address . duplicated ( ) ]\\\n",
    "                        . sort_values(['pid'])\\\n",
    "                        . reset_index(drop=True)\n",
    "    \n",
    "        \n",
    "    loc_id_2_pid = parcels[['loc_id', 'pid']].sort_values(['loc_id', 'pid']).copy()\n",
    "    loc_id_2_pid = loc_id_2_pid[ ~loc_id_2_pid.duplicated() ] \\\n",
    "                        . sort_values(['loc_id','pid'])\\\n",
    "                        . reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    loc_polygons  =  parcels[['loc_id','year','geometry']].sort_values(['loc_id','year'])\n",
    "    loc_polygons  =  loc_polygons[~loc_polygons.duplicated(['loc_id'])].sort_values(['loc_id','year']).reset_index(drop=True)\n",
    "    \n",
    "    loc_polygons [ 'lat'  ]  =  round ( loc_polygons . to_crs ( '+proj=cea' ) . geometry . centroid . to_crs ( loc_polygons . crs ) . y , 7 )\n",
    "    loc_polygons [ 'lon'  ]  =  round ( loc_polygons . to_crs ( '+proj=cea' ) . geometry . centroid . to_crs ( loc_polygons . crs ) . x , 7 )\n",
    "    \n",
    "    loc_polygons = gpd.GeoDataFrame(loc_polygons,geometry=loc_polygons.geometry)\n",
    "\n",
    "\n",
    "\n",
    "    ##221 PROP_IDs in 2013 but not in 2018\n",
    "    ##issue of dup LOC_IDs within a few inches...\n",
    "    mask = (parcels.year==2013)\n",
    "    unique_from_2013 = parcels[mask][~parcels[mask].pid.isin(parcels[parcels.year>2013].pid.unique())][['loc_id','pid','geometry']]\n",
    "    \n",
    "    ##LOC_ID to pid xref\n",
    "    mask = (parcels.year>2013)\n",
    "    loc_pid = parcels[mask][['loc_id', 'year', 'pid']].sort_values(['loc_id', 'year', 'pid']).copy()\n",
    "    loc_pid = loc_pid[ ~loc_pid.duplicated(['loc_id','pid']) ]\n",
    "    loc_pid=loc_pid.sort_values(['loc_id','pid']).reset_index(drop=True)\n",
    "    print('new loc_pid combos by year\\n',loc_pid[loc_pid.year!=2018].groupby('year').count().to_markdown())\n",
    "    \n",
    "    return loc_pid, loc_polygons, pid_2_address\n",
    "\n",
    "\n",
    "def normalize(parcels):\n",
    "    \n",
    "    query = \"\"\"\n",
    "                select ivp.key as ivp,substring(ivp.value,1,3)::int as value\n",
    "                from common.int_value_pairs ivp\n",
    "                where  ivp.item='land_use' order by ivp;\n",
    "            \"\"\"\n",
    "    c2d_2_ivp={}\n",
    "    for x,y in pd.read_sql(query,cnx).to_dict()['value'].items():\n",
    "        c2d_2_ivp[y] = x\n",
    "        \n",
    "    parcels.land_use=parcels.land_use.replace(c2d_2_ivp)\n",
    "    \n",
    "    for col in ['zip', 'owner_city','owner_state',\n",
    "                'zoning','style', 'stories'\n",
    "               ]:\n",
    "    \n",
    "        query = \"\"\"\n",
    "                    select key, value\n",
    "                    from common.int_value_pairs ivp\n",
    "                    where  item='{col}';\n",
    "                \"\"\".format(col=col)\n",
    "        value_2_int={}\n",
    "        for x,y in pd.read_sql(query,cnx).to_dict()['value'].items():\n",
    "            value_2_int[y] = x\n",
    "    \n",
    "        parcels[col]=parcels[col].replace(value_2_int)\n",
    "    \n",
    "    ##periodically add new int_value_pairs\n",
    "    int_value_pairs = pd.DataFrame()\n",
    "    for col in ['owner_city','owner_state','zoning','stories']:\n",
    "        tmp = sorted([x for x in parcels[col].unique() if type(x)==str])\n",
    "        if len(tmp)>0:\n",
    "            query = \"select max(key) from common.int_value_pairs where item='{col}'\"\\\n",
    "                        .format(col=col)\n",
    "            N=pd.read_sql_query(query,cnx)['max'][0]\n",
    "            \n",
    "            ivp = pd.Series(tmp).reset_index().rename(columns={'index':'key',0:'value'})\n",
    "            ivp['item']=col\n",
    "            ivp['key']=N+1+ivp['key']\n",
    "            int_value_pairs = pd.concat([int_value_pairs,ivp])\n",
    "    \n",
    "    print('int_value_pairs adds:\\n',int_value_pairs.to_markdown())\n",
    "    \n",
    "    parcels=parcels.sort_values(['pid','year']).reset_index(drop=True)\n",
    "    \n",
    "    for col in ['land','total']:\n",
    "        for period in [1,3,5]:\n",
    "            parcels[col+'_chg_'+str(period)+'y']=\\\n",
    "                parcels.groupby('pid', sort=False, group_keys=False)[col]\\\n",
    "                    .apply(lambda x: x.pct_change(period))\n",
    "            \n",
    "        parcels[col+'_chg_10y']=\\\n",
    "            parcels.groupby('pid', sort=False, group_keys=False)[col]\\\n",
    "                .apply(lambda x: x.pct_change(7))\n",
    "    \n",
    "    \n",
    "    for col in ['land','total']:\n",
    "        for period in [1,3,5,10]:\n",
    "            mask = ~pd.isnull(parcels[col+'_chg_'+str(period)+'y'])\n",
    "            parcels.loc[mask,col+'_chg_'+str(period)+'y']=\\\n",
    "                parcels.loc[mask,col+'_chg_'+str(period)+'y'].round(6)\n",
    "    \n",
    "    \n",
    "    parcels.stories=parcels.stories.astype(float).fillna(0).astype(int)\n",
    "    \n",
    "    parcels=parcels.replace({'^nan$':''},regex=True)\n",
    "\n",
    "    return parcels,int_value_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f0154-4f94-41bd-ba2a-fc66ed86f082",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982dfd8b-cc9f-4623-9425-b46836815e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "data_dir = './parcels/'\n",
    "\n",
    "data = {}\n",
    "for file in sorted(glob ( data_dir + '*CY*zip' )) :\n",
    "        key  =  file . split ( '_' ) [ -2 ] # FY\n",
    "\n",
    "        data [ key ]  =  get_MassGIS_Level3_TaxParcels ( 'zip+file://'+file )\n",
    "        print ( 'Working' , key )\n",
    "        mask = data [ key ] . duplicated ( 'PROP_ID' )\n",
    "        if mask . any ( ) :\n",
    "            print ( len ( data [ key ] [ mask ] ) , 'Dups in PROP_ID' , key )\n",
    "\n",
    "        ## ArlingtonMA changed street numbering \n",
    "        if key=='FY24':\n",
    "            data[key].LOCATION=data[key].SITE_ADDR.str.split(\" #\").str[1]\n",
    "\n",
    "\n",
    "parcels = pd.DataFrame()\n",
    "for key in sorted(data.keys()):\n",
    "    tmp = create_property_assessments_table(data[key])\n",
    "    parcels=pd.concat([parcels,tmp])\n",
    "\n",
    "## necessary?\n",
    "parcels = remove_dup_loc_id_round_geometry(parcels)\n",
    "\n",
    "\n",
    "print('parcel count\\n',parcels[['year','pid']].groupby('year').count().to_markdown())\n",
    "\n",
    "loc_pid, loc_polygons, pid_2_address = create_geometry(parcels)\n",
    "parcels,int_value_pairs = normalize(parcels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d9004-7f9d-4984-b77c-bae07c7d31bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2af4c-154a-46ae-9bf4-9430a908e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_pid.to_sql(\n",
    "        'loc_pid',\n",
    "        schema='common',\n",
    "        con=cnx,\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ef0ff-238b-4485-93ee-6ccbe271d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels.drop(['geometry','address'],axis=1).to_sql(\n",
    "        'parcels',\n",
    "        schema='property',\n",
    "        con=cnx,\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d60fb9-ba8c-419b-b3b4-16b70bc4a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_polygons.to_postgis(\n",
    "    'loc_polygons',\n",
    "    schema='common',\n",
    "    con=cnx,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f7445b-8901-48d2-8930-6c509502a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_value_pairs.to_sql(\n",
    "        'int_value_pairs',\n",
    "        schema='common',\n",
    "        con=cnx,\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    ) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
